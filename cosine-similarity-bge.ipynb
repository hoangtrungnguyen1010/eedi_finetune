{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 3)) (0.44.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 6)) (0.34.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 9)) (4.44.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 12)) (3.0.1)\n",
      "Requirement already satisfied: trl in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 15)) (0.11.1)\n",
      "Requirement already satisfied: peft in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 18)) (0.13.0)\n",
      "Requirement already satisfied: optimum in /opt/conda/envs/eedi/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 21)) (1.22.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from scikit-learn->-r /workspace/requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from scikit-learn->-r /workspace/requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from scikit-learn->-r /workspace/requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from scikit-learn->-r /workspace/requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/eedi/lib/python3.10/site-packages (from bitsandbytes->-r /workspace/requirements.txt (line 3)) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from accelerate->-r /workspace/requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/eedi/lib/python3.10/site-packages (from accelerate->-r /workspace/requirements.txt (line 6)) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/eedi/lib/python3.10/site-packages (from accelerate->-r /workspace/requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from accelerate->-r /workspace/requirements.txt (line 6)) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from accelerate->-r /workspace/requirements.txt (line 6)) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/eedi/lib/python3.10/site-packages (from transformers->-r /workspace/requirements.txt (line 9)) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from transformers->-r /workspace/requirements.txt (line 9)) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/eedi/lib/python3.10/site-packages (from transformers->-r /workspace/requirements.txt (line 9)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from transformers->-r /workspace/requirements.txt (line 9)) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from transformers->-r /workspace/requirements.txt (line 9)) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from datasets->-r /workspace/requirements.txt (line 12)) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from datasets->-r /workspace/requirements.txt (line 12)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/eedi/lib/python3.10/site-packages (from datasets->-r /workspace/requirements.txt (line 12)) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/eedi/lib/python3.10/site-packages (from datasets->-r /workspace/requirements.txt (line 12)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/eedi/lib/python3.10/site-packages (from datasets->-r /workspace/requirements.txt (line 12)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->-r /workspace/requirements.txt (line 12)) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/eedi/lib/python3.10/site-packages (from datasets->-r /workspace/requirements.txt (line 12)) (3.10.8)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from trl->-r /workspace/requirements.txt (line 15)) (0.8.11)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/envs/eedi/lib/python3.10/site-packages (from optimum->-r /workspace/requirements.txt (line 21)) (15.0.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/eedi/lib/python3.10/site-packages (from optimum->-r /workspace/requirements.txt (line 21)) (1.13.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from aiohttp->datasets->-r /workspace/requirements.txt (line 12)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from aiohttp->datasets->-r /workspace/requirements.txt (line 12)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from aiohttp->datasets->-r /workspace/requirements.txt (line 12)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from aiohttp->datasets->-r /workspace/requirements.txt (line 12)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from aiohttp->datasets->-r /workspace/requirements.txt (line 12)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from aiohttp->datasets->-r /workspace/requirements.txt (line 12)) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from aiohttp->datasets->-r /workspace/requirements.txt (line 12)) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate->-r /workspace/requirements.txt (line 6)) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from requests->transformers->-r /workspace/requirements.txt (line 9)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from requests->transformers->-r /workspace/requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from requests->transformers->-r /workspace/requirements.txt (line 9)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from requests->transformers->-r /workspace/requirements.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/eedi/lib/python3.10/site-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum->-r /workspace/requirements.txt (line 21)) (5.28.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum->-r /workspace/requirements.txt (line 21)) (0.2.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from tyro>=0.5.11->trl->-r /workspace/requirements.txt (line 15)) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from tyro>=0.5.11->trl->-r /workspace/requirements.txt (line 15)) (13.9.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from tyro>=0.5.11->trl->-r /workspace/requirements.txt (line 15)) (1.7.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from coloredlogs->optimum->-r /workspace/requirements.txt (line 21)) (10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from pandas->datasets->-r /workspace/requirements.txt (line 12)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from pandas->datasets->-r /workspace/requirements.txt (line 12)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from pandas->datasets->-r /workspace/requirements.txt (line 12)) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from sympy->optimum->-r /workspace/requirements.txt (line 21)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r /workspace/requirements.txt (line 12)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl->-r /workspace/requirements.txt (line 15)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl->-r /workspace/requirements.txt (line 15)) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes->-r /workspace/requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/eedi/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl->-r /workspace/requirements.txt (line 15)) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r /workspace/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/eedi/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.strings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/sklearn/__init__.py:84\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/sklearn/utils/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/sklearn/utils/_chunking.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/scipy/sparse/__init__.py:293\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# Original code by Travis Oliphant.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Modified and extended by Ed Schofield, Robert Cimrman,\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Nathan Bell, and Jake Vanderplas.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/scipy/sparse/_base.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Base class for sparse matrices\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[1;32m      6\u001b[0m                        get_sum_dtype, isdense, isscalarlike,\n\u001b[1;32m      7\u001b[0m                        matrix, validateaxis,)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misspmatrix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missparse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparray\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseWarning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseEfficiencyWarning\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/scipy/sparse/_sputils.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prod\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m np_long, np_ulong\n\u001b[1;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupcast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misscalarlike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misintlike\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misshape\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missequence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misdense\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mismatrix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_sum_dtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m supported_dtypes \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mbool_, np\u001b[38;5;241m.\u001b[39mbyte, np\u001b[38;5;241m.\u001b[39mubyte, np\u001b[38;5;241m.\u001b[39mshort, np\u001b[38;5;241m.\u001b[39mushort, np\u001b[38;5;241m.\u001b[39mintc,\n\u001b[1;32m     17\u001b[0m                     np\u001b[38;5;241m.\u001b[39muintc, np_long, np_ulong, np\u001b[38;5;241m.\u001b[39mlonglong, np\u001b[38;5;241m.\u001b[39mulonglong,\n\u001b[1;32m     18\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mlongdouble, \n\u001b[1;32m     19\u001b[0m                     np\u001b[38;5;241m.\u001b[39mcomplex64, np\u001b[38;5;241m.\u001b[39mcomplex128, np\u001b[38;5;241m.\u001b[39mclongdouble]\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/scipy/_lib/_util.py:18\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     Optional,\n\u001b[1;32m     12\u001b[0m     Union,\n\u001b[1;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m     14\u001b[0m     TypeVar,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_namespace, is_numpy, size \u001b[38;5;28;01mas\u001b[39;00m xp_size\n\u001b[1;32m     21\u001b[0m AxisError: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mException\u001b[39;00m]\n\u001b[1;32m     22\u001b[0m ComplexWarning: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mWarning\u001b[39;00m]\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/scipy/_lib/_array_api.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnpt\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_api_compat\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     is_array_api_obj,\n\u001b[1;32m     23\u001b[0m     size,\n\u001b[1;32m     24\u001b[0m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[1;32m     25\u001b[0m     device\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray_namespace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_asarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# To enable array API and strict array-like input validation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/scipy/_lib/array_api_compat/numpy/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mabs\u001b[39m, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mround\u001b[39m \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/eedi/lib/python3.10/site-packages/numpy/__init__.py:379\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mac_os_check\u001b[39m():\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;124;03m    Quick Sanity check for Mac OS look for accelerate build bugs.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    Testing numpy polyfit calls init_dgelsd(LAPACK)\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m         c \u001b[38;5;241m=\u001b[39m array([\u001b[38;5;241m3.\u001b[39m, \u001b[38;5;241m2.\u001b[39m, \u001b[38;5;241m1.\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.strings'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train                 = pd.read_csv(\"./eedi-mining-misconceptions-in-mathematics/train.csv\")\n",
    "test                  = pd.read_csv(\"./eedi-mining-misconceptions-in-mathematics/test.csv\")\n",
    "\n",
    "misconception_mapping = pd.read_csv(\"./eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n",
    "sample_submission     = pd.read_csv(\"./eedi-mining-misconceptions-in-mathematics/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misconception_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['A_answer_misconception'] = np.where(train['MisconceptionAId'].notna(),\n",
    "                                           train['AnswerAText'] + '***' + train['MisconceptionAId'].astype(str),\n",
    "                                           None)\n",
    "\n",
    "train['B_answer_misconception'] = np.where(train['MisconceptionBId'].notna(),\n",
    "                                           train['AnswerBText'] + '***' + train['MisconceptionBId'].astype(str),\n",
    "                                           None)\n",
    "\n",
    "train['C_answer_misconception'] = np.where(train['MisconceptionCId'].notna(),\n",
    "                                           train['AnswerCText'] + '***' + train['MisconceptionCId'].astype(str),\n",
    "                                           None)\n",
    "\n",
    "train['D_answer_misconception'] = np.where(train['MisconceptionDId'].notna(),\n",
    "                                           train['AnswerDText'] + '***' + train['MisconceptionDId'].astype(str),\n",
    "                                           None)\n",
    "# test['A_answer_misconception'] = np.where(test['MisconceptionAId'].notna(),\n",
    "#                                            test['AnswerAText'] + '***' + test['MisconceptionAId'].astype(str),\n",
    "#                                            None)\n",
    "\n",
    "# test['B_answer_misconception'] = np.where(test['MisconceptionBId'].notna(),\n",
    "#                                            test['AnswerBText'] + '***' + test['MisconceptionBId'].astype(str),\n",
    "#                                            None)\n",
    "\n",
    "# test['C_answer_misconception'] = np.where(test['MisconceptionCId'].notna(),\n",
    "#                                            test['AnswerCText'] + '***' + test['MisconceptionCId'].astype(str),\n",
    "#                                            None)\n",
    "\n",
    "# test['D_answer_misconception'] = np.where(test['MisconceptionDId'].notna(),\n",
    "#                                            test['AnswerDText'] + '***' + test['MisconceptionDId'].astype(str),\n",
    "#                                            None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[1]['A_answer_misconception']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_question_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"all_question_text\"] = df[\"ConstructName\"] +\" \" +df[\"QuestionText\"]\n",
    "    return df\n",
    "\n",
    "test = make_all_question_text(test)\n",
    "train = make_all_question_text(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_to_long(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['CorrectAnswerText'] = df.apply(lambda row: row[f\"Answer{row['CorrectAnswer']}Text\"], axis=1)\n",
    "\n",
    "    df = pd.melt(\n",
    "        df[\n",
    "            [\n",
    "                \"QuestionId\",\n",
    "                \"all_question_text\",\n",
    "                \"CorrectAnswer\",\n",
    "                \"CorrectAnswerText\",\n",
    "                \"AnswerAText\",\n",
    "                \"AnswerBText\",\n",
    "                \"AnswerCText\",\n",
    "                \"AnswerDText\"\n",
    "            ]\n",
    "        ],\n",
    "        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\", \"CorrectAnswerText\"],\n",
    "        var_name   = 'Answer',\n",
    "        value_name = 'value'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def wide_to_long_train(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['CorrectAnswerText'] = df.apply(lambda row: row[f\"Answer{row['CorrectAnswer']}Text\"], axis=1)\n",
    "\n",
    "    df = pd.melt(\n",
    "        df[\n",
    "            [\n",
    "                \"QuestionId\",\n",
    "                \"all_question_text\",\n",
    "                \"CorrectAnswer\",\n",
    "                \"CorrectAnswerText\",\n",
    "                \"A_answer_misconception\",\n",
    "                \"B_answer_misconception\",\n",
    "                \"C_answer_misconception\",\n",
    "                \"D_answer_misconception\"\n",
    "            ]\n",
    "        ],\n",
    "        id_vars    = [\"QuestionId\", \"all_question_text\", \"CorrectAnswer\", \"CorrectAnswerText\"],\n",
    "        var_name   = 'Answer',\n",
    "        value_name = 'value'\n",
    "    )\n",
    "    df[['AnswerText', 'Misconception_ID']] = df['value'].str.split('\\\\*\\\\*\\\\*', expand=True)\n",
    "    df = df[df['Misconception_ID'].apply(lambda x: isinstance(x, str))]\n",
    "    df['Misconception_ID'] = df['Misconception_ID'].astype(float).astype(int)\n",
    "    return df\n",
    "\n",
    "test_long = wide_to_long(test)\n",
    "train_long = wide_to_long_train(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_long.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"all_text\"] = df[\"all_question_text\"] +\" \" +df[\"value\"]\n",
    "    return df\n",
    "\n",
    "test_long = make_all_text(test_long)\n",
    "test_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_long = test_long.sort_values([\"QuestionId\", \"Answer\"]).reset_index(drop=True)\n",
    "test_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gemma7B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from string import Template\n",
    "from pathlib import Path\n",
    "\n",
    "from torch import nn\n",
    "# Transformer\n",
    "from accelerate import Accelerator\n",
    "import transformers\n",
    "from transformers import (pipeline, AutoTokenizer, AutoModelForCausalLM, \n",
    "                          BitsAndBytesConfig, AutoConfig, TrainingArguments)\n",
    "# Supervised Trainser\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftConfig, PeftModel\n",
    "# Split data into training and test (valid) dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For quantization\n",
    "import bitsandbytes, accelerate\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes, gc\n",
    "import torch\n",
    "\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "# Seed the same seed to all \n",
    "def seed_everything(seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "def clear_memory():\n",
    "    libc.malloc_trim(0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "# Set the GPUs\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name = 'gemma_7b'\n",
    "    model_paths = {'gemma_7b': \"google/gemma-7b\"}\n",
    "    model_path = model_paths[model_name]\n",
    "    \n",
    "    # Model training argument\n",
    "    data_path = '/kaggle/input/gemma-rewrite-nbroad/nbroad-v2.csv'\n",
    "    model_save_path =  f'{model_name}_adapter'\n",
    "    max_length=512 # truncate the text to the first 150 words to avoid OOM issues.\n",
    "    NROWS = 1000 # Read 1000 texts from dataset\n",
    "    batch_size = 1\n",
    "    lr = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(row):\n",
    "    question = f\"{row['all_question_text']} The correct answer is: {row['CorrectAnswerText']}. The wrong answer is: {row['value']}. What is the misconception here?\"\n",
    "    answer = misconception_mapping.loc[misconception_mapping['MisconceptionId'] == row['Misconception_ID'], 'MisconceptionName'].iloc[0]\n",
    "    template = f\"Question:\\n{question}\\n\\nAnswer:\\n{answer}\"\n",
    "    return [template]\n",
    "\n",
    "def train_model(model, tokenizer, training_df = None):\n",
    "    # Load the training data\n",
    "    # Create the dataset\n",
    "    if training_df is None:\n",
    "        training_df = pd.read_csv(CFG.data_path, nrows=CFG.NROWS)\n",
    "    training_df['formatted_text'] = training_df.apply(formatting_func, axis=1)\n",
    "\n",
    "    training_ds = Dataset.from_pandas(training_df)\n",
    "    \n",
    "    # Tokenizer \n",
    "    training_ds = training_ds.map(lambda samples: tokenizer(samples[\"formatted_text\"]), batched=True)\n",
    "    # Add PEFT (lora) layer\n",
    "    lora_config = LoraConfig(r=32, # Rank\n",
    "                             lora_alpha=32,\n",
    "                             target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \n",
    "                                             \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "                             lora_dropout=0.05,\n",
    "                             bias=\"none\",\n",
    "                             task_type=TaskType.CAUSAL_LM)\n",
    "    # Training arguments\n",
    "    args = TrainingArguments(\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=CFG.batch_size,\n",
    "            gradient_accumulation_steps=16,\n",
    "            warmup_steps=5,\n",
    "            max_steps=100,\n",
    "            learning_rate=CFG.lr,\n",
    "            fp16=True,\n",
    "            logging_steps=1,\n",
    "            output_dir=\"outputs\",\n",
    "            optim=\"paged_adamw_8bit\",\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "    # Create a trainer (supervised fine-tuned trainer)\n",
    "    trainer = SFTTrainer(model=model,\n",
    "                         train_dataset=training_ds,\n",
    "                         args=args,\n",
    "                         peft_config=lora_config)\n",
    "    trainer.train()\n",
    "    # Save the model\n",
    "    trainer.save_model(CFG.model_save_path)\n",
    "    tokenizer.save_pretrained(CFG.model_save_path)\n",
    "    print(f\"Save the model to {CFG.model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    accelerator = Accelerator()\n",
    "    # Use quantization technique to reduce the memory usage\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)\n",
    "    # Load the model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "                                CFG.model_path,\n",
    "                                device_map = \"auto\",\n",
    "                                trust_remote_code = True,\n",
    "                                quantization_config=quantization_config)\n",
    "    model = accelerator.prepare(model)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, tokenizer, train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gemma 2B keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "# !pip install -q -U keras-nlp\n",
    "# !pip install -q -U keras>=3\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"\n",
    "\n",
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#importing 7b takes too much memory and causes the kaggle notebook to restart.\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the input sequence length to 512 (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = 512\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    beta_1=0.9,          # Adjust beta_1 parameter\n",
    "    beta_2=0.999         # Adjust beta_2 parameter\n",
    "    )\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 64.\n",
    "gemma_lm.backbone.enable_lora(rank=64)\n",
    "# gemma_lm.backbone.load_lora_weights('/kaggle/input/gemma_lora_math/tensorflow2/default/1/model.lora.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = []\n",
    "questions = []\n",
    "for index, row in train_long.iterrows():\n",
    "    question = row['all_question_text'] + 'The correct answer is: ' + row['CorrectAnswerText'] + 'The wrong answer is: ' + row['AnswerText'] +'. What is the misconception here? '\n",
    "    answer = misconception_mapping.loc[misconception_mapping['MisconceptionId'] == row['Misconception_ID'], 'MisconceptionName'].iloc[0]\n",
    "\n",
    "    template = (f\"Question:\\n{question}\\n\\nAnswer:\\n{answer}\")\n",
    "    training_dataset.append(template)\n",
    "    questions.append(question)\n",
    "gemma_lm.fit(training_dataset, epochs=5, batch_size=1)\n",
    "gemma_lm.backbone.save_lora_weights('/kaggle/working/model.lora.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "predicted_answer = []\n",
    "answer_id = []\n",
    "# train_long['answer_alphabet'] = train_long[\"Answer\"].str.extract(r'Answer([A-Z])Text$')\n",
    "\n",
    "for index, row in train_long[:100].iterrows():\n",
    "    if row['CorrectAnswer'] != row['answer_alphabet']:\n",
    "        ID = str(int(row['QuestionId'])) + '_' + str(row['answer_alphabet'])\n",
    "        \n",
    "        question = row['all_question_text'] + 'The correct answer is: ' + r*w['CorrectAnswerText'] + 'The wrong answer is: ' + row['value'] +'. What is the misconception here? '\n",
    "\n",
    "        template = (f\"Question:\\n{question}\\n\\nAnswer:\\n\")\n",
    "        response = gemma_lm.generate(template, max_length=256)\n",
    "#         print(response)\n",
    "        match = re.search(r\"Answer:\\s*(.*)\", response)        \n",
    "        if match:\n",
    "            # Extract the character after 'Answer' and before 'Text'\n",
    "            answer_text = match.group(1)\n",
    "        else:\n",
    "            answer_text = response\n",
    "#         print(answer_text)\n",
    "\n",
    "        answer_id.append(ID)\n",
    "        predicted_answer.append(answer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(answer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_LORA_WT_PATH = '/kaggle/working/model.lora.h5'\n",
    "# gemma_lm.backbone.load_lora_weights(MODEL_LORA_WT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model and tokenizer for embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n",
    "model     = AutoModel.from_pretrained('/kaggle/input/bge-small-en-v1.5/transformers/bge/2')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "MisconceptionName = list(misconception_mapping['MisconceptionName'].values)\n",
    "per_gpu_batch_size = 8\n",
    "\n",
    "\n",
    "def prepare_inputs(text, tokenizer, device):\n",
    "    tokenizer_outputs = tokenizer.batch_encode_plus(\n",
    "        text,\n",
    "        padding        = True,\n",
    "        return_tensors = 'pt',\n",
    "        max_length     = 1024,\n",
    "        truncation     = True\n",
    "    )\n",
    "    result = {\n",
    "        'input_ids': tokenizer_outputs.input_ids.to(device),\n",
    "        'attention_mask': tokenizer_outputs.attention_mask.to(device),\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "all_ctx_vector = []\n",
    "for mini_batch in tqdm(range(0, len(MisconceptionName[:]), per_gpu_batch_size)):\n",
    "    mini_context          = MisconceptionName[mini_batch:mini_batch+ per_gpu_batch_size]\n",
    "    encoded_input         = prepare_inputs(mini_context,tokenizer,device)\n",
    "    sentence_embeddings   = model(**encoded_input)[0][:, 0]\n",
    "    sentence_embeddings   = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    all_ctx_vector.append(sentence_embeddings.detach().cpu().numpy())\n",
    "\n",
    "all_ctx_vector = np.concatenate(all_ctx_vector, axis=0)\n",
    "print(\"Sentence embeddings:\", sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MisconceptionName[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_ctx_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_vector = []\n",
    "per_gpu_batch_size = 8\n",
    "\n",
    "for mini_batch in tqdm(\n",
    "        range(0, len(predicted_answer[:]), per_gpu_batch_size)):\n",
    "    mini_context = predicted_answer[mini_batch:mini_batch\n",
    "                                           + per_gpu_batch_size]\n",
    "    encoded_input = prepare_inputs(mini_context,tokenizer,device)\n",
    "    sentence_embeddings = model(\n",
    "        **encoded_input)[0][:, 0]\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    \n",
    "    all_text_vector.append(sentence_embeddings.detach().cpu().numpy())\n",
    "\n",
    "all_text_vector = np.concatenate(all_text_vector, axis=0)\n",
    "print(all_text_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cos_sim_arr = cosine_similarity(all_text_vector, all_ctx_vector)\n",
    "test_sorted_indices = np.argsort(-test_cos_sim_arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sorted_indices[:, :25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submit File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "\n",
    "res[\"MisconceptionId\"] = test_sorted_indices[:, :25].tolist()\n",
    "res[\"MisconceptionId\"] = res[\"MisconceptionId\"].apply(lambda x: ' '.join(map(str, x)))\n",
    "res[\"QuestionId_Answer\"] = answer_id\n",
    "# filter correct row\n",
    "# test_long = test_long[test_long[\"CorrectAnswer\"] != test_long[\"Answer_alphabet\"]]\n",
    "submission = res[[\"QuestionId_Answer\", \"MisconceptionId\"]].reset_index(drop=True)\n",
    "# Extract QuestionId and Answer from the 'QuestionId_Answer' column\n",
    "submission[['QuestionId', 'Answer']] = submission['QuestionId_Answer'].str.split('_', expand=True)\n",
    "\n",
    "# Convert 'QuestionId' to integer for proper numerical sorting\n",
    "submission['QuestionId'] = submission['QuestionId'].astype(int)\n",
    "\n",
    "# Sort by 'QuestionId' first and then by 'Answer' alphabetically\n",
    "submission_sorted = submission.sort_values(by=['QuestionId', 'Answer']).reset_index(drop=True)\n",
    "\n",
    "# Display the result\n",
    "print(submission_sorted[['QuestionId_Answer', 'MisconceptionId']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_long['answer_alphabet'] = train_long[\"Answer\"].str.extract(r'([A-Z])_answer_misconception$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9551816,
     "sourceId": 82695,
     "sourceType": "competition"
    },
    {
     "datasetId": 5771943,
     "sourceId": 9487585,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5774890,
     "sourceId": 9491629,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 141220873,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 166559676,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 169374254,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 169375546,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 169375992,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 169501845,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 3301,
     "modelInstanceId": 8332,
     "sourceId": 11394,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 33601,
     "modelInstanceId": 23286,
     "sourceId": 27644,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 125638,
     "modelInstanceId": 101444,
     "sourceId": 120594,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "eedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
